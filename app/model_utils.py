# app/model_utils.py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Dict, Any

class ZeroShotClassifier:
    def __init__(self, model_dir: str = None):
        import os

        # é¦–å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è·å–æ¨¡å‹è·¯å¾„
        if model_dir is None:
            model_dir = os.environ.get("MODEL_PATH", "/app/model")

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ğŸ“‚ å°è¯•ä»ä»¥ä¸‹è·¯å¾„åŠ è½½æ¨¡å‹: {model_dir}")

        # æŒ‡å®šæ¨¡å‹ä»æœ¬åœ°ç›®å½•åŠ è½½ï¼ˆè€Œéä»ç½‘ç»œï¼‰
        model_path = model_dir

        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path).to(self.device)
            self.model.eval()
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            print("âš ï¸ è¯·ç¡®è®¤ä»¥ä¸‹å‡ ç‚¹:")
            print("  1. æ¨¡å‹æ–‡ä»¶æ˜¯å¦å·²å¤åˆ¶åˆ°Dockeré•œåƒä¸­")
            print("  2. æ˜¯å¦ä½¿ç”¨äº†æ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
            print("  3. æˆ–è€…è€ƒè™‘ä½¿ç”¨å·æŒ‚è½½: docker run -v æœ¬åœ°æ¨¡å‹è·¯å¾„:/app/model ...")
            raise

    def classify(self, text: str, labels: List[str]) -> Dict[str, Any]:
        results = []

        for label in labels:
            inputs = self.tokenizer(
                text,
                label,
                return_tensors="pt",
                truncation=True,
                padding=True
            ).to(self.device)

            with torch.no_grad():
                logits = self.model(**inputs).logits
                probs = torch.nn.functional.softmax(logits, dim=1)[0]  # [entailment, neutral, contradiction]

            # å‡è®¾ NLI æ¨¡å‹è¾“å‡ºé¡ºåºæ˜¯ [entailment, neutral, contradiction]
            # å–ç¬¬0ä¸ªå€¼ï¼ˆentailmentï¼‰ä½œä¸ºè¯¥æ–‡æœ¬ä¸æ ‡ç­¾çš„åŒ¹é…åº¦
            entailment_score = probs[0].item()
            results.append({
                "label": label,
                "score": entailment_score
            })

        # æŒ‰å¾—åˆ†é™åºæ’åº
        sorted_results = sorted(results, key=lambda x: x["score"], reverse=True)
        best_label = sorted_results[0]["label"]
        best_score = sorted_results[0]["score"]

        return {
            "text": text,
            "labels": sorted_results,
            "predicted_label": best_label,
            "predicted_score": best_score
        }