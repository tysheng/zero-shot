# app/model_utils.py
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from typing import List, Dict, Any

class ZeroShotClassifier:
    def __init__(self, model_dir: str = "/app/model"):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")

        # æŒ‡å®šæ¨¡å‹ä»æœ¬åœ°ç›®å½•åŠ è½½ï¼ˆè€Œéä»ç½‘ç»œï¼‰
        model_path = model_dir

        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path).to(self.device)
        self.model.eval()

    def classify(self, text: str, labels: List[str]) -> Dict[str, Any]:
        results = []

        for label in labels:
            inputs = self.tokenizer(
                text,
                label,
                return_tensors="pt",
                truncation=True,
                padding=True
            ).to(self.device)

            with torch.no_grad():
                logits = self.model(**inputs).logits
                probs = torch.nn.functional.softmax(logits, dim=1)[0]  # [entailment, neutral, contradiction]

            # å‡è®¾ NLI æ¨¡å‹è¾“å‡ºé¡ºåºæ˜¯ [entailment, neutral, contradiction]
            # å–ç¬¬0ä¸ªå€¼ï¼ˆentailmentï¼‰ä½œä¸ºè¯¥æ–‡æœ¬ä¸æ ‡ç­¾çš„åŒ¹é…åº¦
            entailment_score = probs[0].item()
            results.append({
                "label": label,
                "score": entailment_score
            })

        # æŒ‰å¾—åˆ†é™åºæ’åº
        sorted_results = sorted(results, key=lambda x: x["score"], reverse=True)
        best_label = sorted_results[0]["label"]
        best_score = sorted_results[0]["score"]

        return {
            "text": text,
            "labels": sorted_results,
            "predicted_label": best_label,
            "predicted_score": best_score
        }